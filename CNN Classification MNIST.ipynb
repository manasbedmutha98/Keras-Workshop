{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of the MNIST data using CNNs\n",
    "### By [Manas Bedmutha](https://github.com/manasbedmutha98)",
    "\n",
    "The MNIST Dataset has 28 x 28 black and white images of digits from 0 to 9. It is one of the most common datasets for starting up with deep learning. It comes in built in the keras package.\n",
    "\n",
    "This notebook will walk you through the developing a classification model for the dataset using a <b>Convolutional Neural Network</b> with the help of the <b>Model API</b> from Keras.\n",
    "\n",
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, MaxPooling2D\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "from keras.activations import *\n",
    "from keras.optimizers import *\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "\n",
    "MNIST comes as a part of the keras datasets. It contains 60,000 training images while 10,000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Display one image?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "The labels refer to the expected classification output for a given image. They are converted from singular to one-hot encoded values from 0 to 9. \n",
    "\n",
    "That is, if a given image corresponds to 5, its encoding will be [0,0,0,0,0,1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_test = (X_test.astype(np.float32) - 127.5)/127.5\n",
    "\n",
    "X_train = X_train[:,:,:,np.newaxis]\n",
    "X_test = X_test[:,:,:,np.newaxis]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "#y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Keras Model\n",
    "\n",
    "We will build the model using the Sequential API. Since we only wan't MLP based network, we will use Dense layers for fully connecting neurons.Simply go on adding a layer as it pleases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 4, 64)          18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 2, 2, 64)          256       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 36,298\n",
      "Trainable params: 36,106\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "In = Input(shape=(28,28,1))\n",
    "x = Conv2D(32, kernel_size=3, strides=2, padding=\"same\",activation='relu')(In)\n",
    "x = MaxPooling2D(pool_size=2,strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=3, strides=2, padding=\"same\",activation='relu')(x)\n",
    "x = MaxPooling2D(pool_size=2,strides=2, padding=\"same\")(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "y = Dense(num_classes, activation='softmax')(x)\n",
    "                                                                                    \n",
    "model = Model(inputs=In,outputs=y)                                                                                   \n",
    "                                                                                   \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is compiled using an optimizer, a loss function and a metric for performance improvement. \n",
    "- The loss function is used to depict how far is the current model from the ideal answer\n",
    "- The optimizer refers to the method that will be used to minimize the loss\n",
    "- The metrics correspond to how we want to measure the performance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing\n",
    "\n",
    "- Training is done using the function fit(). We train out network for 5 epochs.\n",
    "- Testing is done using the predict() function. We can also use evaluate() but since we want to later generate a classificiation report, we will use the former\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 44s 738us/step - loss: 0.2600 - acc: 0.9252\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 44s 741us/step - loss: 0.0910 - acc: 0.9733\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 42s 696us/step - loss: 0.0650 - acc: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f19985caf10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_check = model.predict(X_test)\n",
    "\n",
    "y_pred = np.array([np.argmax(y_check[j]) for j in range(len(y_check))])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can be evaluated by multiple metrics. Here we are using a confusion matrix and classification report from Sklearn and evaluate function by Keras. \n",
    "- The confusion matrix has y_true on the vertical and y_pred on the horizontal axes respectively; it gives a measure of how many y_true happened to be classified in each of the categories.\n",
    "- Classification Report is a collection of class wise Precision and Recall scores\n",
    "- Evaluate() returns the accuracy for a particular model on the data given to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 976    1    0    0    0    0    2    1    0    0]\n",
      " [   0 1132    2    0    1    0    0    0    0    0]\n",
      " [   3    3 1012    7    0    0    2    3    2    0]\n",
      " [   0    0    4  993    0    5    0    4    4    0]\n",
      " [   1    0    0    0  969    0    3    1    0    8]\n",
      " [   2    0    0    9    1  870    7    1    2    0]\n",
      " [   5    4    1    0    2    3  941    0    2    0]\n",
      " [   0    6    9    5    1    0    0  999    1    7]\n",
      " [   4    0    3    4    3    2    2    2  951    3]\n",
      " [   6    2    0    6    8    4    1    5    4  973]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      1.00      0.99       980\n",
      "          1       0.99      1.00      0.99      1135\n",
      "          2       0.98      0.98      0.98      1032\n",
      "          3       0.97      0.98      0.98      1010\n",
      "          4       0.98      0.99      0.99       982\n",
      "          5       0.98      0.98      0.98       892\n",
      "          6       0.98      0.98      0.98       958\n",
      "          7       0.98      0.97      0.98      1028\n",
      "          8       0.98      0.98      0.98       974\n",
      "          9       0.98      0.96      0.97      1009\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. [Keras' official example](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) on Github\n",
    "2. [Documentation References](https://keras.io/) for more info about every function/layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
