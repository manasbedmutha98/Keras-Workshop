{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of the MNIST data using Fully Connected Network\n",
    "\n",
    "The MNIST Dataset has 28 x 28 black and white images of digits from 0 to 9. It is one of the most common datasets for starting up with deep learning. It comes in built in the keras package.\n",
    "\n",
    "This notebook will walk you through the developing a classification model for the dataset using Fully Connected Networks.\n",
    "\n",
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import *\n",
    "from keras.optimizers import *\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset\n",
    "\n",
    "MNIST comes as a part of the keras datasets. It contains 60,000 training images while 10,000 test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "#X_train = X_train.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (10000, 28, 28))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "The labels are converted from singular to one-hot encoded values from 0 to 9. \n",
    "\n",
    "That is, if a given image corresponds to 5, its encoding will be [0,0,0,0,0,1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "#y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Keras Model\n",
    "\n",
    "We will build the model using the Sequential API. Since we only wan't MLP based network, we will use Dense layers for fully connecting neurons.Simply go on adding a layer as it pleases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Flatten(input_shape=(28,28)))\n",
    "model1.add(Dense(512,activation='relu'))\n",
    "#model1.add(Dropout(0.2))\n",
    "model1.add(Dense(256,activation='tanh'))\n",
    "#model1.add(Dropout(0.2))\n",
    "model1.add(Dense(num_classes,activation='softmax'))\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is compiled using an optimizer, a loss function and a metric for performance improvement. \n",
    "- The loss function is used to depict how far is the current model from the ideal answer\n",
    "- The optimizer refers to the method that will be used to minimize the loss\n",
    "- The metrics correspond to how we want to measure the performance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='mse', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing\n",
    "\n",
    "Training is done using the function fit(). We train out network for 5 epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 22s 371us/step - loss: 0.0213 - acc: 0.8449\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 23s 389us/step - loss: 0.0078 - acc: 0.9493\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 21s 356us/step - loss: 0.0062 - acc: 0.9595\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 21s 350us/step - loss: 0.0055 - acc: 0.9641\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0048 - acc: 0.9682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa34cf78810>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(X_train,y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_check = model1.predict(X_test)\n",
    "y_pred = np.array([np.argmax(y_check[j]) for j in range(len(y_check))])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 941,    0,    0,   25,    0,    8,    3,    0,    2,    1],\n",
       "       [   0, 1124,    0,    7,    0,    1,    1,    0,    2,    0],\n",
       "       [  12,    9,  791,  189,    5,    2,    8,    8,    8,    0],\n",
       "       [   0,    0,    0, 1005,    0,    0,    0,    3,    2,    0],\n",
       "       [   8,    8,    1,    9,  897,    1,   10,    2,    7,   39],\n",
       "       [   5,    2,    0,   91,    0,  774,    6,    0,   11,    3],\n",
       "       [  11,    5,    0,   13,    1,   15,  902,    0,   10,    1],\n",
       "       [   7,   16,    9,   59,    1,    2,    0,  858,    1,   75],\n",
       "       [   0,    8,    1,  150,    3,    4,    2,    1,  801,    4],\n",
       "       [   6,   16,    0,   56,    9,    2,    0,    5,    7,  908]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.96      0.96       980\n",
      "          1       0.95      0.99      0.97      1135\n",
      "          2       0.99      0.77      0.86      1032\n",
      "          3       0.63      1.00      0.77      1010\n",
      "          4       0.98      0.91      0.95       982\n",
      "          5       0.96      0.87      0.91       892\n",
      "          6       0.97      0.94      0.95       958\n",
      "          7       0.98      0.83      0.90      1028\n",
      "          8       0.94      0.82      0.88       974\n",
      "          9       0.88      0.90      0.89      1009\n",
      "\n",
      "avg / total       0.92      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. [Keras' official example](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) on Github\n",
    "2. [Documentation References](https://keras.io/) for more info about every function/layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras' Example\n",
    "\n",
    "# print(X_train.shape[0], 'train samples')\n",
    "# print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# num_classes = 10\n",
    "\n",
    "# # convert class vectors to binary class matrices\n",
    "# y_train = to_categorical(y_train, num_classes)\n",
    "# y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Flatten(input_shape=(28,28)))\n",
    "# model.add(Dense(1024,activation='relu'))\n",
    "# #model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer=RMSprop(),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# history = model.fit(X_train, y_train,\n",
    "#                     batch_size=128,\n",
    "#                     epochs=5,\n",
    "#                     verbose=1,\n",
    "#                     validation_data=(X_test, y_test))\n",
    "# score = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
