{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Classification of the CIFAR10 data using CNNs\n",
    "\n",
    "The CIFAR10 has 32 x 32 x 3 (channels) images of 10 different categories which have been numbered as digits from 0 to 9. It is also one of the most common datasets for starting up with deep learning. Its download script comes inbuilt with the keras package.\n",
    "\n",
    "This notebook will walk you through the developing a classification model for the dataset using a <b>Convolutional Neural Network</b> with the help of the <b>Sequential API</b> from Keras.\n",
    "\n",
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from keras.layers import Input, Flatten, Dense, Dropout, MaxPooling2D\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.convolutional import Conv2D\n",
    "\n",
    "from keras.activations import *\n",
    "from keras.optimizers import *\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the dataset\n",
    "\n",
    "CIFAR10 comes as a part of the keras datasets. It contains 50,000 training images while 10,000 test images. Running the next cell will download it to your local systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "- Since we are using a convolutional network we do not need to flatten the array into 1D.\n",
    "- Normalize pixel values between -1 and 1 (and Input type should be float)\n",
    "- There are 10 classes so in order to compute the cross entropy loss function we need to one-hot encoded vectors.\n",
    "- The labels refer to the expected classification output for a given image. They are converted from singular to one-hot encoded values from 0 to 9. That is, if a given image corresponds to 5, its encoding will be [0,0,0,0,0,1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "X_test = (X_test.astype(np.float32) - 127.5)/127.5\n",
    "\n",
    "# X_train = X_train[:,:,:,np.newaxis]\n",
    "# X_test = X_test[:,:,:,np.newaxis]\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "#y_test = to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Keras Model\n",
    "\n",
    "Construct a model using the sequential API with the following instructions:\n",
    "\n",
    "- Inputs are normalized using BatchNormaliation followed by a Dropout layer with a rate of 0.3\n",
    "- Then add a 2D convolutional layer with a kernel of 3x3 with 16 filters\n",
    "- Activate the output with a relu using an Activation layer separately\n",
    "- Output from the convolutional layer goes through a MaxPooling layer of size 2\n",
    "- Add another 2D convolutional layer but ensure that the shape remains 'same' as previous layer having 32 filters\n",
    "- Output from the convolutional layer goes through a MaxPooling layer\n",
    "- Then Flatten the output and add a Dropout layer with a rate of 0.3\n",
    "- Connect the output to a Dense layer containing 100 neurons followed by a BatchNormalization \n",
    "- and finally connect to the output layer with an softmax activation function\n",
    "\n",
    "Print the model summary to see the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add model here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final model is compiled using an optimizer, a loss function and a metric for performance improvement. \n",
    "- The loss function is used to depict how far is the current model from the ideal answer\n",
    "- The optimizer refers to the method that will be used to minimize the loss\n",
    "- The metrics correspond to how we want to measure the performance of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adagrad(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing\n",
    "\n",
    "- Training is done using the function fit(). We train out network for 5 epochs.\n",
    "- Testing is done using the predict() function. We can also use evaluate() but since we want to later generate a classificiation report, we will use the former\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_check = model.predict(X_test)\n",
    "\n",
    "y_pred = np.array([np.argmax(y_check[j]) for j in range(len(y_check))])\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "1. [Keras' official example](https://github.com/keras-team/keras/blob/master/examples/mnist_mlp.py) on Github\n",
    "2. [Documentation References](https://keras.io/) for more info about every function/layer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
